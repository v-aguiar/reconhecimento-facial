{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-aguiar/reconhecimento-facial/blob/main/Face_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGFzqi6rB_Ki"
      },
      "source": [
        "# Reconhecimento facial usando OpenCV via Webcam\n",
        "\n",
        "Esse projeto utiliza o modelo haarcascades da OpenCv para realizar a detecção facial.\n",
        "Também é realizado um processo de captura de amostrar do rosto do usuário.\n",
        "\n",
        "Após a captura de amostras e treinamento do modelo, o sistema é capaz de detectar rostos e entre \"Desconhecido\" ou \"Nome_do_usuário\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A578sDm_-BJ9"
      },
      "source": [
        "# import dependencies\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceRecognitionSystem:\n",
        "    def __init__(self):\n",
        "        self.face_cascade = cv2.CascadeClassifier(\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "        )\n",
        "        self.recognizer = None\n",
        "        self.labels = {}\n",
        "        self.is_capturing = False\n",
        "        self.should_stop = False\n",
        "\n",
        "    def init_webcam(self):\n",
        "        display(HTML('''\n",
        "            <div id=\"webcam-container\"></div>\n",
        "            <button onclick=\"document.getElementById('webcam-container').innerHTML = ''\">\n",
        "                Parar Webcam\n",
        "            </button>\n",
        "        '''))\n",
        "\n",
        "    def js_to_image(self, js_reply):\n",
        "        image_bytes = b64decode(js_reply.split(',')[1])\n",
        "        jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "        return cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "    def start_video_stream(self):\n",
        "        js = Javascript('''\n",
        "          var video;\n",
        "          var div = null;\n",
        "          var stream;\n",
        "          var captureCanvas;\n",
        "          var imgElement;\n",
        "          var labelElement;\n",
        "\n",
        "          var pendingResolve = null;\n",
        "          var shutdown = false;\n",
        "\n",
        "          function removeDom() {\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            video.remove();\n",
        "            div.remove();\n",
        "            video = null;\n",
        "            div = null;\n",
        "            stream = null;\n",
        "            imgElement = null;\n",
        "            captureCanvas = null;\n",
        "            labelElement = null;\n",
        "          }\n",
        "\n",
        "          function onAnimationFrame() {\n",
        "            if (!shutdown) {\n",
        "              window.requestAnimationFrame(onAnimationFrame);\n",
        "            }\n",
        "            if (pendingResolve) {\n",
        "              var result = \"\";\n",
        "              if (!shutdown) {\n",
        "                captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "                result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "              }\n",
        "              var lp = pendingResolve;\n",
        "              pendingResolve = null;\n",
        "              lp(result);\n",
        "            }\n",
        "          }\n",
        "\n",
        "          async function createDom() {\n",
        "            if (div !== null) {\n",
        "              return stream;\n",
        "            }\n",
        "\n",
        "            div = document.createElement('div');\n",
        "            div.style.border = '2px solid black';\n",
        "            div.style.padding = '3px';\n",
        "            div.style.width = '100%';\n",
        "            div.style.maxWidth = '600px';\n",
        "            document.body.appendChild(div);\n",
        "\n",
        "            const modelOut = document.createElement('div');\n",
        "            modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "            labelElement = document.createElement('span');\n",
        "            labelElement.innerText = 'No data';\n",
        "            labelElement.style.fontWeight = 'bold';\n",
        "            modelOut.appendChild(labelElement);\n",
        "            div.appendChild(modelOut);\n",
        "\n",
        "            video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            video.width = div.clientWidth - 6;\n",
        "            video.setAttribute('playsinline', '');\n",
        "            video.onclick = () => { shutdown = true; };\n",
        "            stream = await navigator.mediaDevices.getUserMedia(\n",
        "                {video: { facingMode: \"environment\"}});\n",
        "            div.appendChild(video);\n",
        "\n",
        "            imgElement = document.createElement('img');\n",
        "            imgElement.style.position = 'absolute';\n",
        "            imgElement.style.zIndex = 1;\n",
        "            imgElement.onclick = () => { shutdown = true; };\n",
        "            div.appendChild(imgElement);\n",
        "\n",
        "            const instruction = document.createElement('div');\n",
        "            instruction.innerHTML =\n",
        "                '<span style=\"color: red; font-weight: bold;\">' +\n",
        "                'When finished, click here or on the video to stop this demo</span>';\n",
        "            div.appendChild(instruction);\n",
        "            instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            captureCanvas = document.createElement('canvas');\n",
        "            captureCanvas.width = 640; //video.videoWidth;\n",
        "            captureCanvas.height = 480; //video.videoHeight;\n",
        "            window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "            return stream;\n",
        "          }\n",
        "          async function stream_frame(label, imgData) {\n",
        "            if (shutdown) {\n",
        "              removeDom();\n",
        "              shutdown = false;\n",
        "              return '';\n",
        "            }\n",
        "\n",
        "            var preCreate = Date.now();\n",
        "            stream = await createDom();\n",
        "\n",
        "            var preShow = Date.now();\n",
        "            if (label != \"\") {\n",
        "              labelElement.innerHTML = label;\n",
        "            }\n",
        "\n",
        "            if (imgData != \"\") {\n",
        "              var videoRect = video.getClientRects()[0];\n",
        "              imgElement.style.top = videoRect.top + \"px\";\n",
        "              imgElement.style.left = videoRect.left + \"px\";\n",
        "              imgElement.style.width = videoRect.width + \"px\";\n",
        "              imgElement.style.height = videoRect.height + \"px\";\n",
        "              imgElement.src = imgData;\n",
        "            }\n",
        "\n",
        "            var preCapture = Date.now();\n",
        "            var result = await new Promise(function(resolve, reject) {\n",
        "              pendingResolve = resolve;\n",
        "            });\n",
        "            shutdown = false;\n",
        "\n",
        "            return {'create': preShow - preCreate,\n",
        "                    'show': preCapture - preShow,\n",
        "                    'capture': Date.now() - preCapture,\n",
        "                    'img': result};\n",
        "          }\n",
        "        ''')\n",
        "        display(js)\n",
        "\n",
        "    def get_video_frame(self, label, bbox):\n",
        "        return eval_js(f'stream_frame(\"{label}\", \"{bbox}\")')\n",
        "\n",
        "    def capture_samples(self, user_name='username', num_samples=100): # Caso queira trocar o nome do usuário, alterar aqui\n",
        "        self.is_capturing = True\n",
        "        self.should_stop = False\n",
        "        os.makedirs(f'dataset/{user_name}', exist_ok=True)\n",
        "\n",
        "        try:\n",
        "            self.start_video_stream()\n",
        "            count = 0\n",
        "            bbox = ''\n",
        "\n",
        "            while count < num_samples and not self.should_stop:\n",
        "                js_reply = self.get_video_frame('Capturando...', bbox)\n",
        "                if not js_reply:\n",
        "                    break\n",
        "\n",
        "                frame = self.js_to_image(js_reply[\"img\"])\n",
        "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "                faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "                for (x,y,w,h) in faces:\n",
        "                    face_roi = cv2.resize(gray[y:y+h, x:x+w], (200, 200))\n",
        "                    cv2.imwrite(f'dataset/{user_name}/face_{count}.jpg', face_roi)\n",
        "                    count += 1\n",
        "                    print(f'Amostras capturadas: {count}/{num_samples}')\n",
        "                    time.sleep(0.3)\n",
        "\n",
        "                # Verificação para parada manual\n",
        "                if count >= num_samples:\n",
        "                    print(\"Captura concluída!\")\n",
        "                    break\n",
        "\n",
        "        finally:\n",
        "            self.is_capturing = False\n",
        "            display(HTML('<script>document.querySelector(\"button\").click()</script>'))\n",
        "            print(\"Webcam liberada\")\n",
        "\n",
        "    def train_model(self):\n",
        "        self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "        faces = []\n",
        "        labels = []\n",
        "        label_ids = {}\n",
        "        current_id = 0\n",
        "\n",
        "        for root, dirs, _ in os.walk(\"dataset\"):\n",
        "            for dir_name in dirs:\n",
        "                label_ids[dir_name] = current_id\n",
        "                for file in os.listdir(f\"{root}/{dir_name}\"):\n",
        "                    path = os.path.join(root, dir_name, file)\n",
        "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                    faces.append(img)\n",
        "                    labels.append(current_id)\n",
        "                current_id += 1\n",
        "\n",
        "        self.recognizer.train(faces, np.array(labels))\n",
        "        self.labels = {v:k for k,v in label_ids.items()}\n",
        "        self.recognizer.save(\"face_recognizer.yml\")\n",
        "        print(\"Modelo treinado com sucesso!\")\n",
        "\n",
        "    def run_recognition(self):\n",
        "      if not self.recognizer:\n",
        "          if os.path.exists(\"face_recognizer.yml\"):\n",
        "              self.recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "              self.recognizer.read(\"face_recognizer.yml\")\n",
        "          else:\n",
        "              raise Exception(\"Modelo não treinado!\")\n",
        "\n",
        "      try:\n",
        "          self.start_video_stream()\n",
        "          bbox = ''\n",
        "\n",
        "          while True:\n",
        "              js_reply = self.get_video_frame('Reconhecendo...', bbox)\n",
        "              if not js_reply:\n",
        "                  break\n",
        "\n",
        "              # Processar frame\n",
        "              frame = self.js_to_image(js_reply[\"img\"])\n",
        "              gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "              faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "              # Criar overlay\n",
        "              overlay = frame.copy()\n",
        "              for (x,y,w,h) in faces:\n",
        "                  roi_gray = gray[y:y+h, x:x+w]\n",
        "                  label_id, conf = self.recognizer.predict(roi_gray)\n",
        "                  name = self.labels.get(label_id, \"Desconhecido\")\n",
        "                  color = (0,255,0) if conf < 70 else (0,0,255)\n",
        "\n",
        "                  cv2.rectangle(overlay, (x,y), (x+w,y+h), color, 2)\n",
        "                  cv2.putText(overlay, f\"{name} ({conf:.1f})\",\n",
        "                            (x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "              # Codificar para JPEG\n",
        "              _, buffer = cv2.imencode('.jpg', overlay)\n",
        "              bbox = 'data:image/jpg;base64,' + b64encode(buffer).decode('utf-8')\n",
        "\n",
        "      finally:\n",
        "            display(HTML('<script>document.querySelector(\"button\").click()</script>'))\n",
        "            print(\"Reconhecimento encerrado\")"
      ],
      "metadata": {
        "id": "whjqcutY9SwK"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso:\n",
        "system = FaceRecognitionSystem()"
      ],
      "metadata": {
        "id": "QxeyFnLL-1K6"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Capturar amostras (executar separadamente)\n",
        "system.capture_samples(num_samples=50)  # Clique na webcam para parar antes do término"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1rtExPXg-2g5",
        "outputId": "72735d41-3254-489f-d7a7-b41b1f92bb1d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "          var video;\n",
              "          var div = null;\n",
              "          var stream;\n",
              "          var captureCanvas;\n",
              "          var imgElement;\n",
              "          var labelElement;\n",
              "\n",
              "          var pendingResolve = null;\n",
              "          var shutdown = false;\n",
              "\n",
              "          function removeDom() {\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            video.remove();\n",
              "            div.remove();\n",
              "            video = null;\n",
              "            div = null;\n",
              "            stream = null;\n",
              "            imgElement = null;\n",
              "            captureCanvas = null;\n",
              "            labelElement = null;\n",
              "          }\n",
              "\n",
              "          function onAnimationFrame() {\n",
              "            if (!shutdown) {\n",
              "              window.requestAnimationFrame(onAnimationFrame);\n",
              "            }\n",
              "            if (pendingResolve) {\n",
              "              var result = \"\";\n",
              "              if (!shutdown) {\n",
              "                captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "                result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "              }\n",
              "              var lp = pendingResolve;\n",
              "              pendingResolve = null;\n",
              "              lp(result);\n",
              "            }\n",
              "          }\n",
              "\n",
              "          async function createDom() {\n",
              "            if (div !== null) {\n",
              "              return stream;\n",
              "            }\n",
              "\n",
              "            div = document.createElement('div');\n",
              "            div.style.border = '2px solid black';\n",
              "            div.style.padding = '3px';\n",
              "            div.style.width = '100%';\n",
              "            div.style.maxWidth = '600px';\n",
              "            document.body.appendChild(div);\n",
              "\n",
              "            const modelOut = document.createElement('div');\n",
              "            modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "            labelElement = document.createElement('span');\n",
              "            labelElement.innerText = 'No data';\n",
              "            labelElement.style.fontWeight = 'bold';\n",
              "            modelOut.appendChild(labelElement);\n",
              "            div.appendChild(modelOut);\n",
              "\n",
              "            video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            video.width = div.clientWidth - 6;\n",
              "            video.setAttribute('playsinline', '');\n",
              "            video.onclick = () => { shutdown = true; };\n",
              "            stream = await navigator.mediaDevices.getUserMedia(\n",
              "                {video: { facingMode: \"environment\"}});\n",
              "            div.appendChild(video);\n",
              "\n",
              "            imgElement = document.createElement('img');\n",
              "            imgElement.style.position = 'absolute';\n",
              "            imgElement.style.zIndex = 1;\n",
              "            imgElement.onclick = () => { shutdown = true; };\n",
              "            div.appendChild(imgElement);\n",
              "\n",
              "            const instruction = document.createElement('div');\n",
              "            instruction.innerHTML =\n",
              "                '<span style=\"color: red; font-weight: bold;\">' +\n",
              "                'When finished, click here or on the video to stop this demo</span>';\n",
              "            div.appendChild(instruction);\n",
              "            instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            captureCanvas = document.createElement('canvas');\n",
              "            captureCanvas.width = 640; //video.videoWidth;\n",
              "            captureCanvas.height = 480; //video.videoHeight;\n",
              "            window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "            return stream;\n",
              "          }\n",
              "          async function stream_frame(label, imgData) {\n",
              "            if (shutdown) {\n",
              "              removeDom();\n",
              "              shutdown = false;\n",
              "              return '';\n",
              "            }\n",
              "\n",
              "            var preCreate = Date.now();\n",
              "            stream = await createDom();\n",
              "\n",
              "            var preShow = Date.now();\n",
              "            if (label != \"\") {\n",
              "              labelElement.innerHTML = label;\n",
              "            }\n",
              "\n",
              "            if (imgData != \"\") {\n",
              "              var videoRect = video.getClientRects()[0];\n",
              "              imgElement.style.top = videoRect.top + \"px\";\n",
              "              imgElement.style.left = videoRect.left + \"px\";\n",
              "              imgElement.style.width = videoRect.width + \"px\";\n",
              "              imgElement.style.height = videoRect.height + \"px\";\n",
              "              imgElement.src = imgData;\n",
              "            }\n",
              "\n",
              "            var preCapture = Date.now();\n",
              "            var result = await new Promise(function(resolve, reject) {\n",
              "              pendingResolve = resolve;\n",
              "            });\n",
              "            shutdown = false;\n",
              "\n",
              "            return {'create': preShow - preCreate,\n",
              "                    'show': preCapture - preShow,\n",
              "                    'capture': Date.now() - preCapture,\n",
              "                    'img': result};\n",
              "          }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amostras capturadas: 1/50\n",
            "Amostras capturadas: 2/50\n",
            "Amostras capturadas: 3/50\n",
            "Amostras capturadas: 4/50\n",
            "Amostras capturadas: 5/50\n",
            "Amostras capturadas: 6/50\n",
            "Amostras capturadas: 7/50\n",
            "Amostras capturadas: 8/50\n",
            "Amostras capturadas: 9/50\n",
            "Amostras capturadas: 10/50\n",
            "Amostras capturadas: 11/50\n",
            "Amostras capturadas: 12/50\n",
            "Amostras capturadas: 13/50\n",
            "Amostras capturadas: 14/50\n",
            "Amostras capturadas: 15/50\n",
            "Amostras capturadas: 16/50\n",
            "Amostras capturadas: 17/50\n",
            "Amostras capturadas: 18/50\n",
            "Amostras capturadas: 19/50\n",
            "Amostras capturadas: 20/50\n",
            "Amostras capturadas: 21/50\n",
            "Amostras capturadas: 22/50\n",
            "Amostras capturadas: 23/50\n",
            "Amostras capturadas: 24/50\n",
            "Amostras capturadas: 25/50\n",
            "Amostras capturadas: 26/50\n",
            "Amostras capturadas: 27/50\n",
            "Amostras capturadas: 28/50\n",
            "Amostras capturadas: 29/50\n",
            "Amostras capturadas: 30/50\n",
            "Amostras capturadas: 31/50\n",
            "Amostras capturadas: 32/50\n",
            "Amostras capturadas: 33/50\n",
            "Amostras capturadas: 34/50\n",
            "Amostras capturadas: 35/50\n",
            "Amostras capturadas: 36/50\n",
            "Amostras capturadas: 37/50\n",
            "Amostras capturadas: 38/50\n",
            "Amostras capturadas: 39/50\n",
            "Amostras capturadas: 40/50\n",
            "Amostras capturadas: 41/50\n",
            "Amostras capturadas: 42/50\n",
            "Amostras capturadas: 43/50\n",
            "Amostras capturadas: 44/50\n",
            "Amostras capturadas: 45/50\n",
            "Amostras capturadas: 46/50\n",
            "Amostras capturadas: 47/50\n",
            "Amostras capturadas: 48/50\n",
            "Amostras capturadas: 49/50\n",
            "Amostras capturadas: 50/50\n",
            "Captura concluída!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script>document.querySelector(\"button\").click()</script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Webcam liberada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Treinar (executar após captura)\n",
        "system.train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASS9295R-4P6",
        "outputId": "808eb1e8-f078-4d7a-832d-5174475e6c49"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo treinado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Reconhecer (executar após treino)\n",
        "system.run_recognition()  # Clique na webcam para encerrar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OeiHQQk_-5oS",
        "outputId": "515ac81e-d1d0-442a-8e93-e6b452320c9a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "          var video;\n",
              "          var div = null;\n",
              "          var stream;\n",
              "          var captureCanvas;\n",
              "          var imgElement;\n",
              "          var labelElement;\n",
              "\n",
              "          var pendingResolve = null;\n",
              "          var shutdown = false;\n",
              "\n",
              "          function removeDom() {\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            video.remove();\n",
              "            div.remove();\n",
              "            video = null;\n",
              "            div = null;\n",
              "            stream = null;\n",
              "            imgElement = null;\n",
              "            captureCanvas = null;\n",
              "            labelElement = null;\n",
              "          }\n",
              "\n",
              "          function onAnimationFrame() {\n",
              "            if (!shutdown) {\n",
              "              window.requestAnimationFrame(onAnimationFrame);\n",
              "            }\n",
              "            if (pendingResolve) {\n",
              "              var result = \"\";\n",
              "              if (!shutdown) {\n",
              "                captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "                result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "              }\n",
              "              var lp = pendingResolve;\n",
              "              pendingResolve = null;\n",
              "              lp(result);\n",
              "            }\n",
              "          }\n",
              "\n",
              "          async function createDom() {\n",
              "            if (div !== null) {\n",
              "              return stream;\n",
              "            }\n",
              "\n",
              "            div = document.createElement('div');\n",
              "            div.style.border = '2px solid black';\n",
              "            div.style.padding = '3px';\n",
              "            div.style.width = '100%';\n",
              "            div.style.maxWidth = '600px';\n",
              "            document.body.appendChild(div);\n",
              "\n",
              "            const modelOut = document.createElement('div');\n",
              "            modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "            labelElement = document.createElement('span');\n",
              "            labelElement.innerText = 'No data';\n",
              "            labelElement.style.fontWeight = 'bold';\n",
              "            modelOut.appendChild(labelElement);\n",
              "            div.appendChild(modelOut);\n",
              "\n",
              "            video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            video.width = div.clientWidth - 6;\n",
              "            video.setAttribute('playsinline', '');\n",
              "            video.onclick = () => { shutdown = true; };\n",
              "            stream = await navigator.mediaDevices.getUserMedia(\n",
              "                {video: { facingMode: \"environment\"}});\n",
              "            div.appendChild(video);\n",
              "\n",
              "            imgElement = document.createElement('img');\n",
              "            imgElement.style.position = 'absolute';\n",
              "            imgElement.style.zIndex = 1;\n",
              "            imgElement.onclick = () => { shutdown = true; };\n",
              "            div.appendChild(imgElement);\n",
              "\n",
              "            const instruction = document.createElement('div');\n",
              "            instruction.innerHTML =\n",
              "                '<span style=\"color: red; font-weight: bold;\">' +\n",
              "                'When finished, click here or on the video to stop this demo</span>';\n",
              "            div.appendChild(instruction);\n",
              "            instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            captureCanvas = document.createElement('canvas');\n",
              "            captureCanvas.width = 640; //video.videoWidth;\n",
              "            captureCanvas.height = 480; //video.videoHeight;\n",
              "            window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "            return stream;\n",
              "          }\n",
              "          async function stream_frame(label, imgData) {\n",
              "            if (shutdown) {\n",
              "              removeDom();\n",
              "              shutdown = false;\n",
              "              return '';\n",
              "            }\n",
              "\n",
              "            var preCreate = Date.now();\n",
              "            stream = await createDom();\n",
              "\n",
              "            var preShow = Date.now();\n",
              "            if (label != \"\") {\n",
              "              labelElement.innerHTML = label;\n",
              "            }\n",
              "\n",
              "            if (imgData != \"\") {\n",
              "              var videoRect = video.getClientRects()[0];\n",
              "              imgElement.style.top = videoRect.top + \"px\";\n",
              "              imgElement.style.left = videoRect.left + \"px\";\n",
              "              imgElement.style.width = videoRect.width + \"px\";\n",
              "              imgElement.style.height = videoRect.height + \"px\";\n",
              "              imgElement.src = imgData;\n",
              "            }\n",
              "\n",
              "            var preCapture = Date.now();\n",
              "            var result = await new Promise(function(resolve, reject) {\n",
              "              pendingResolve = resolve;\n",
              "            });\n",
              "            shutdown = false;\n",
              "\n",
              "            return {'create': preShow - preCreate,\n",
              "                    'show': preCapture - preShow,\n",
              "                    'capture': Date.now() - preCapture,\n",
              "                    'img': result};\n",
              "          }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script>document.querySelector(\"button\").click()</script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconhecimento encerrado\n"
          ]
        }
      ]
    }
  ]
}